{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import pickle\n", "import random\n", "import shutil\n", "from concurrent.futures import ThreadPoolExecutor\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import librosa\n", "import librosa.display\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "from PIL import Image\n", "from librosa import feature\n", "from sklearn.model_selection import train_test_split\n", "from tensorflow.keras.utils import to_categorical\n", "from sklearn.preprocessing import LabelEncoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def split_data_and_create_folders(base_path, output_base_path):\n", "    genres = os.listdir(base_path)\n", "    data = []\n\n", "    # Collect all file paths and their corresponding genres\n", "    for genre in genres:\n", "        genre_path = os.path.join(base_path, genre)\n", "        for filename in os.listdir(genre_path):\n", "            if filename.endswith('.png'):\n", "                file_path = os.path.join(genre_path, filename)\n", "                data.append((file_path, genre))\n\n", "    # Split the data into train, test, and eval\n", "    train, test = train_test_split(data, test_size=0.2, random_state=42)\n", "    train, eval = train_test_split(train, test_size=0.2, random_state=42)\n", "    def copy_files(file_list, set_name):\n", "        for file_path, genre in file_list:\n", "            dest_folder = os.path.join(output_base_path, set_name, genre)\n", "            if not os.path.exists(dest_folder):\n", "                os.makedirs(dest_folder)\n", "            shutil.copy(file_path, dest_folder)\n\n", "    # Copy files to respective directories\n", "    copy_files(train, 'train')\n", "    copy_files(test, 'test')\n", "    copy_files(eval, 'validation')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_classification_dataset(data_path, split_phase):\n", "    X = []\n", "    y = []\n", "    for data_type in ['test']:\n", "        genres = sorted(os.listdir(os.path.join(data_path, data_type)))\n", "        genre_to_index = {genre: i for i, genre in enumerate(genres)}\n", "        for genre in genres:\n", "            print(f\"Processing genre: {genre}\")\n", "            genre_path = os.path.join(data_path, data_type, genre)\n", "            for image_file in os.listdir(genre_path):\n", "                if image_file.endswith('.png'):\n", "                    image_path = os.path.join(genre_path, image_file)\n", "                    image = Image.open(image_path).convert('L')\n", "                    image_array = np.array(image) / 255.0\n", "                    X.append(image_array)\n", "                    y.append(genre_to_index[genre])\n", "        X = np.array(X)\n", "        y = to_categorical(np.array(y), num_classes=len(genres))\n", "        X_phase_2 = X[int(len(X) * split_phase):]\n", "        y_phase_2 = y[int(len(y) * split_phase):]\n", "        phase_data = os.path.join(data_path, 'phase_2')\n", "        if not os.path.exists(phase_data):\n", "            os.makedirs(phase_data)\n", "        print(\"Saving the datasets...\")\n", "        np.save(f\"{phase_data}/X_{data_type}.npy\", X_phase_2)\n", "        np.save(f\"{phase_data}/y_{data_type}.npy\", y_phase_2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def npy_to_spectrogram_png(target_path):\n", "    genres = os.listdir(target_path)\n", "    for genre in genres:\n", "        genre_path = os.path.join(target_path, genre)\n", "        for filename in os.listdir(genre_path):\n", "            if filename.endswith('.npy'):\n", "                original_filename = os.path.join(genre_path, filename)\n", "                png_filename = filename.replace('.npy', '.png')\n", "                target_filename = os.path.join(genre_path, png_filename)\n", "                if os.path.exists(target_filename):\n", "                    continue\n", "                spectrogram_path = os.path.join(genre_path, filename)\n", "                S_DB = np.load(spectrogram_path)\n", "                plt.figure(figsize=(3, 3))\n", "                librosa.display.specshow(S_DB, x_axis='time', y_axis='mel')\n", "                plt.axis('off')\n", "                plt.savefig(target_filename, bbox_inches='tight', pad_inches=0)\n", "                plt.close()\n", "                os.remove(original_filename)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_file(file_path, target_genre_path, genre, sr=None, data_length=30):\n", "    assert data_length in [3, 30], \"Data length must be 3 or 30 seconds\"\n", "    if file_path.endswith('.wav'):\n", "        try:\n", "            x, sr = librosa.load(file_path, sr=sr)\n", "        except Exception as e:\n", "            print(f\"Error processing {file_path}: {e}\")\n", "            return\n", "        sr = int(sr)\n", "        if data_length == 3:\n", "            frames = librosa.util.frame(x=x, frame_length=3 * sr, hop_length=3 * sr)\n", "            for i, frame in enumerate(frames.T):\n", "                S = librosa.feature.melspectrogram(y=frame, sr=sr)\n", "                S_DB = librosa.power_to_db(S, ref=np.max)\n", "                filename = os.path.basename(file_path)\n", "                new_filename = f\"{'.'.join(filename.split('.')[:2])}.{i}.png\"\n", "                np.save(os.path.join(target_genre_path, new_filename), S_DB)\n", "        else:\n", "            S = librosa.feature.melspectrogram(y=x, sr=sr)\n", "            S_DB = librosa.power_to_db(S, ref=np.max)\n", "            np.save(os.path.join(target_genre_path, f\"{os.path.basename(file_path).replace('.wav', '')}\"), S_DB)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def wav_to_spectrogram(source_path, target_path, data_length):\n", "    genres = os.listdir(source_path)\n", "    with ThreadPoolExecutor() as executor:\n", "        futures = []\n", "        for genre in genres:\n", "            print(f\"Processing genre: {genre}\")\n", "            genre_path = os.path.join(source_path, genre)\n", "            target_genre_path = os.path.join(target_path, genre)\n", "            Path(target_genre_path).mkdir(parents=True, exist_ok=True)\n", "            for filename in os.listdir(genre_path):\n", "                file_path = os.path.join(genre_path, filename)\n", "                args = (file_path, target_genre_path, genre, 22050, data_length)\n", "                futures.append(executor.submit(process_file, *args))\n\n", "        # Wait for all threads to complete\n", "        for future in futures:\n", "            future.result()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_pairs_dataset(base_dir=\"Data/3_sec_datasets/B_W_datasets\", dist_matrix_path='Data/3_sec_datasets/dist_matrix_3_sec.pkl',\n", "                         split_phase=None, convert_to_grey=False):\n", "    dist_matrix = pd.read_pickle(dist_matrix_path)\n", "    datasets = ['train', 'test', 'validation']\n", "    # datasets = ['validation']\n", "    for dataset in datasets:\n", "        print(f'Creating pairs for {dataset} dataset...')\n", "        X_pairs = []\n", "        y_pairs = []\n", "        for genre in os.listdir(os.path.join(base_dir, dataset)):\n", "            genre_dir = os.path.join(base_dir, dataset, genre)\n", "            images = [f for f in os.listdir(genre_dir) if f.endswith('.png')]\n", "            for img_filename in images:\n", "                img1_path = os.path.join(genre_dir, img_filename)\n", "                if convert_to_grey:\n", "                    image1 = Image.open(img1_path).convert('L')\n", "                else:\n", "                    image1 = Image.open(img1_path).convert('RGB')\n", "                img1 = np.array(image1) / 255.0\n", "                pair_img_filename = random.choice(images)\n", "                img2_path = os.path.join(genre_dir, pair_img_filename)\n", "                if convert_to_grey:\n", "                    image2 = Image.open(img2_path).convert('L')\n", "                else:\n", "                    image2 = Image.open(img2_path).convert('RGB')\n", "                img2 = np.array(image2) / 255.0\n", "                try:\n", "                    concatenated_images = np.stack((img1, img2))\n", "                    dist = dist_matrix.loc[img_filename.replace('png', 'wav'), pair_img_filename.replace('png', 'wav')]\n", "                    X_pairs.append(concatenated_images)\n", "                    y_pairs.append(dist)\n", "                except:\n", "                    print(f'Error with {img_filename} and {pair_img_filename}')\n", "                    continue\n", "        X_pairs = np.array(X_pairs)\n", "        y_pairs = np.array(y_pairs)\n", "        if split_phase:\n", "            pairs_dataset_dir = os.path.join(base_dir, 'phase_1', 'pairs_dataset')\n", "            if not os.path.exists(pairs_dataset_dir):\n", "                os.makedirs(pairs_dataset_dir)\n", "            X_phase_1 = X_pairs[:int(len(X_pairs) * split_phase)]\n", "            y_phase_1 = y_pairs[:int(len(y_pairs) * split_phase)]\n", "            dataset = 'val' if dataset == 'validation' else dataset\n", "            np.save(os.path.join(pairs_dataset_dir, f'X_{dataset}_pairs.npy'), X_phase_1)\n", "            np.save(os.path.join(pairs_dataset_dir, f'y_{dataset}_pairs.npy'), y_phase_1)\n", "        else:\n", "            pairs_dataset_dir = os.path.join(base_dir, 'pairs_dataset')\n", "            if not os.path.exists(pairs_dataset_dir):\n", "                os.makedirs(pairs_dataset_dir)\n", "            np.save(os.path.join(pairs_dataset_dir, f'X_{dataset}_pairs.npy'), X_pairs)\n", "            np.save(os.path.join(pairs_dataset_dir, f'y_{dataset}_pairs.npy'), y_pairs)\n", "        print(f'Created {len(X_pairs)} pairs for {dataset} dataset.')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_triplets_dataset_threshold(base_dir='Data/3_sec_datasets/B_W_datasets',\n", "                            dist_matrix_path='Data/3_sec_datasets/dist_matrix_3_sec.pkl',\n", "                            threshold=0.985, split_phase=0.5):\n", "    dist_matrix = pd.read_pickle(dist_matrix_path)\n", "    dist_matrix.index = [f.replace('wav', 'png') for f in dist_matrix.index]\n", "    dist_matrix.columns = [f.replace('wav', 'png') for f in dist_matrix.columns]\n", "    np.fill_diagonal(dist_matrix.values, np.nan)\n", "    similarity_mask = dist_matrix > threshold\n", "    datasets = ['train', 'test', 'validation']\n", "    triplets_dataset_dir = os.path.join(base_dir, 'phase_1', 'triplets_dataset')\n", "    if not os.path.exists(triplets_dataset_dir):\n", "        os.makedirs(triplets_dataset_dir)\n", "    for dataset in datasets:\n", "        print(f'Creating triplets for {dataset} dataset...')\n", "        anchors = []\n", "        positives = []\n", "        negatives = []\n", "        dataset_images = []\n", "        for genre in os.listdir(os.path.join(base_dir, dataset)):\n", "            genre_dir = os.path.join(base_dir, dataset, genre)\n", "            images = [f for f in os.listdir(genre_dir) if f in dist_matrix.index]\n", "            dataset_images.extend(images)\n", "        dataset_similarity_mask = similarity_mask.loc[dataset_images, dataset_images] > threshold\n", "        for anchor in dataset_images:\n", "            anchor_genre = anchor.split('.')[0]\n", "            positive_candidates = dataset_similarity_mask.loc[\n", "                anchor, dataset_similarity_mask.loc[anchor]].index.tolist()\n", "            negative_candidates = dataset_similarity_mask.loc[\n", "                anchor, ~dataset_similarity_mask.loc[anchor]].index.tolist()\n", "            positive_candidates = [p for p in positive_candidates if p != anchor]\n", "            negative_candidates = [n for n in negative_candidates if n != anchor]\n", "            if positive_candidates and negative_candidates:\n", "                positive = random.choice(positive_candidates)\n", "                positive_genre = positive.split('.')[0]\n", "                negative = random.choice(negative_candidates)\n", "                negative_genre = negative.split('.')[0]\n", "                anchor_path = os.path.join(base_dir, dataset, anchor_genre, anchor)\n", "                positive_path = os.path.join(base_dir, dataset, positive_genre, positive)\n", "                negative_path = os.path.join(base_dir, dataset, negative_genre, negative)\n", "                anchor_img = np.array(Image.open(anchor_path).convert('L')) / 255.0\n", "                positive_img = np.array(Image.open(positive_path).convert('L')) / 255.0\n", "                negative_img = np.array(Image.open(negative_path).convert('L')) / 255.0\n", "                anchors.append(anchor_img)\n", "                positives.append(positive_img)\n", "                negatives.append(negative_img)\n", "        anchors = np.array(anchors)[:int(len(anchors) * split_phase)]\n", "        positives = np.array(positives)[:int(len(positives) * split_phase)]\n", "        negatives = np.array(negatives)[:int(len(negatives) * split_phase)]\n", "        np.save(os.path.join(triplets_dataset_dir, f'anchors_{dataset}.npy'), anchors)\n", "        np.save(os.path.join(triplets_dataset_dir, f'positives_{dataset}.npy'), positives)\n", "        np.save(os.path.join(triplets_dataset_dir, f'negatives_{dataset}.npy'), negatives)\n", "        print(f'Created {len(anchors)} triplets for {dataset} dataset.')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_triplets_dataset(base_dir='Data/3_sec_datasets/B_W_datasets',\n", "                            dist_matrix_path='Data/3_sec_datasets/dist_matrix_3_sec.pkl',\n", "                            split_phase=None, convert_to_grey=False):\n", "    dist_matrix = pd.read_pickle(dist_matrix_path)\n", "    dist_matrix.index = [f.replace('wav', 'png') for f in dist_matrix.index]\n", "    dist_matrix.columns = [f.replace('wav', 'png') for f in dist_matrix.columns]\n", "    triplets_dataset_dir = os.path.join(base_dir, 'triplets_dataset')\n", "    if not os.path.exists(triplets_dataset_dir):\n", "        os.makedirs(triplets_dataset_dir)\n", "    for dataset in ['train', 'test', 'validation']:\n", "        print(f'Creating triplets for {dataset} dataset...')\n", "        anchors = []\n", "        positives = []\n", "        negatives = []\n", "        genre_to_images = {}\n", "        for genre in os.listdir(os.path.join(base_dir, dataset)):\n", "            genre_dir = os.path.join(base_dir, dataset, genre)\n", "            genre_to_images[genre] = [f for f in os.listdir(genre_dir) if f.endswith('.png')]\n", "        for genre, images in genre_to_images.items():\n", "            for anchor in images:\n", "                positive_candidates = [img for img in images if img != anchor]\n", "                if positive_candidates:\n", "                    positive = random.choice(positive_candidates)\n", "                    different_genres = [g for g in genre_to_images if g != genre]\n", "                    negative_genre = random.choice(different_genres)\n", "                    negative_candidates = genre_to_images[negative_genre]\n", "                    negative = random.choice(negative_candidates)\n", "                    anchor_path = os.path.join(base_dir, dataset, genre, anchor)\n", "                    positive_path = os.path.join(base_dir, dataset, genre, positive)\n", "                    negative_path = os.path.join(base_dir, dataset, negative_genre, negative)\n", "                    if convert_to_grey:\n", "                        anchor_img = np.array(Image.open(anchor_path).convert('L')) / 255.0\n", "                        positive_img = np.array(Image.open(positive_path).convert('L')) / 255.0\n", "                        negative_img = np.array(Image.open(negative_path).convert('L')) / 255.0\n", "                    else:\n", "                        anchor_img = np.array(Image.open(anchor_path).convert('RGB')) / 255.0\n", "                        positive_img = np.array(Image.open(positive_path).convert('RGB')) / 255.0\n", "                        negative_img = np.array(Image.open(negative_path).convert('RGB')) / 255.0\n", "                    anchors.append(anchor_img)\n", "                    positives.append(positive_img)\n", "                    negatives.append(negative_img)\n", "        if split_phase:\n", "            limit = int(len(anchors) * split_phase)\n", "            anchors = np.array(anchors)[:limit]\n", "            positives = np.array(positives)[:limit]\n", "            negatives = np.array(negatives)[:limit]\n", "            dataset = 'val' if dataset == 'validation' else dataset\n", "            np.save(os.path.join(triplets_dataset_dir, f'anchors_{dataset}.npy'), anchors)\n", "            np.save(os.path.join(triplets_dataset_dir, f'positives_{dataset}.npy'), positives)\n", "            np.save(os.path.join(triplets_dataset_dir, f'negatives_{dataset}.npy'), negatives)\n", "        else:\n", "            dataset = 'val' if dataset == 'validation' else dataset\n", "            np.save(os.path.join(triplets_dataset_dir, f'anchors_{dataset}.npy'), np.array(anchors))\n", "            np.save(os.path.join(triplets_dataset_dir, f'positives_{dataset}.npy'), np.array(positives))\n", "            np.save(os.path.join(triplets_dataset_dir, f'negatives_{dataset}.npy'), np.array(negatives))\n", "        print(f'Created {len(anchors)} triplets for {dataset} dataset.')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_images_to_np_dataset(folder_path):\n", "    for phase in ['train', 'test', 'validation']:\n", "        print(f'Loading {phase} images...')\n", "        images = []\n", "        labels = []\n", "        for genre in os.listdir(os.path.join(folder_path, phase)):\n", "            print(f'Loading {genre} images...')\n", "            genre_path = os.path.join(folder_path, phase, genre)\n", "            for image_file in os.listdir(genre_path):\n", "                if image_file.endswith('.png'):\n", "                    image_path = os.path.join(genre_path, image_file)\n", "                    image = Image.open(image_path).convert('RGB')\n", "                    images.append(np.array(image))\n", "                    labels.append(genre)\n", "        images = np.array(images) / 255.0\n", "        a = set(labels)\n", "        labels = pd.get_dummies(labels).values\n", "        np.save(f\"{os.path.join(folder_path)}/classifier_dataset/X_{phase}.npy\", images)\n", "        np.save(f\"{os.path.join(folder_path)}/classifier_dataset/y_{phase}.npy\", labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def split_xgb_dataset(datasets_path, datasets):\n", "    label_encoder = LabelEncoder()\n", "    for dataset in datasets:\n", "        df = pd.read_csv(f'{datasets_path}/{dataset}_datasets/features_{dataset}.csv', index_col=0)\n\n", "        # Encode labels\n", "        df['label'] = label_encoder.fit_transform(df['label'])\n\n", "        # Splitting the data into train, validation, and test sets\n", "        train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n", "        train, eval = train_test_split(train, test_size=0.25, random_state=42, stratify=train['label'])\n\n", "        # Separate features and labels\n", "        X_train, y_train = train.drop('label', axis=1), train['label']\n", "        X_eval, y_eval = eval.drop('label', axis=1), eval['label']\n", "        X_test, y_test = test.drop('label', axis=1), test['label']\n", "        pickle_path = f'{datasets_path}/{dataset}_datasets/xgboost_datasets'\n", "        pickle.dump(X_train, open(f'{pickle_path}/X_train.pkl', 'wb'))\n", "        pickle.dump(y_train, open(f'{pickle_path}/y_train.pkl', 'wb'))\n", "        pickle.dump(X_eval, open(f'{pickle_path}/X_eval.pkl', 'wb'))\n", "        pickle.dump(y_eval, open(f'{pickle_path}/y_eval.pkl', 'wb'))\n", "        pickle.dump(X_test, open(f'{pickle_path}/X_test.pkl', 'wb'))\n", "        pickle.dump(y_test, open(f'{pickle_path}/y_test.pkl', 'wb'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    # build_classification_dataset('Data/3_sec_datasets/B_W_datasets', split_phase)\n", "    # split_data_and_create_folders('Data/3_sec_datasets/3_sec_spectograms_full', 'Data/3_sec_datasets/RGB_datasets')\n", "    # process_images_and_split('Data/3_sec_datasets/3_sec_spectograms_full')\n", "    # wav_to_spectrogram('Data/genres_original', 'Data/30_sec_datasets/30_sec_spectograms_full', 30)\n", "    # npy_to_spectrogram_png('Data/30_sec_datasets/30_sec_spectograms_full')\n", "    # for folder in ['train', 'test', 'validation'][::-1]:\n", "    #     convert_images_to_np_dataset(f'Data/3_sec_datasets/{folder}')\n", "    datasets = ['30_sec', '3_sec']\n", "    datasets_path = 'Data'\n", "    split_xgb_dataset(datasets_path, datasets)\n", "    print(1/0)\n", "    for data_type in [30, 3]:\n", "        convert_images_to_np_dataset(f'Data/{data_type}_sec_datasets/RGB_datasets')\n", "        # create_pairs_dataset(base_dir=f'Data/{data_type}_sec_datasets/RGB_datasets', dist_matrix_path=f'Data/{data_type}_sec_datasets/dist_matrix_{data_type}_sec.pkl', split_phase=split_phase)\n", "        # create_triplets_dataset(base_dir=f'Data/{data_type}_sec_datasets/RGB_datasets')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}